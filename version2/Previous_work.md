# 之前的工作

- 2025.3.21

更新web的chatglm和KGshow部分

- 2025.3.2

完成intent_detection 更新web代码

- 2025.3.1

更新ELECTRA，DeBERTa和bert的部分代码。模型已上传huggingface。

完成Restatement.py

- 2025.2.26

完成DeBERTa部分的代码，更新test

- 2025.2.4

完成ELECTRA部分代码。

- 2025.1.3

拉huggingface代码完成实体识别。

实现web端QA界面的“问题重述”，“实体识别”，“意图识别”部分。

- 2025.1.2

实现web端的introduce、KGshow和QA部分内容。

实现langchain的部分内容（chain连接模块，流输出，带记忆的聊天（多轮对话））。

- 2024.12.28

在ack_LLM.py中，尝试了一下prompt进行**问题重述**，让他“提问你认为回答此文本提到的问题需要了解的专业问题”，LLM总是输出：

> 糖尿病的预防与治疗

“预防”，“治疗”属于两个类别，无奈进行多分类（意图）。编写multi_intent_detection_bert.py，使用BCE（内置SIGMOD）进行多意图识别，发现效果并不好。

> 代码原理是:
>
> **真实标签（labels）**：
>
> > [[1, 0, 0],  # 第一个样本的真实标签 
> >
> > [0, 1, 0]]  # 第二个样本的真实标签
>
> **Logits 输出**：
>
> > [[ 2.0, -1.5,  0.3],  # 第一个样本的 logits 
> >
> > [-0.8,  2.5, -3.0]]  # 第二个样本的 logits
>
> **Sigmoid 激活:**
>
> > torch.sigmoid([[ 2.0, -1.5,  0.3],               
> >
> > [-0.8,  2.5, -3.0]])
> >
> > = [[0.8808, 0.1824, 0.5744], # 第一个样本的概率  
> >
> > [0.3100, 0.9241, 0.0474]]  # 第二个样本的概率
>
>  **二值化：**
>
> > preds = [[1, 0, 1],  # 第一个样本的预测        
> >
> > [0, 1, 0]]  # 第二个样本的预测
>
> **计算正确预测数**：
>
> > (preds == labels) = [[True, True, True],   # 第一个样本错了一个                     
> >
> > [True, True, True]]  # 第二个样本全对
> >
> > 正确数量 = 6（所有标签全对）
>
> accuracy = correct / total = 5 / 6 = 83.3（即 83.3% 准确率）
>
> ****

> 请输入问句（输入'退出'结束）：糖尿病如果进行检查，糖尿病会遗传给下一代吗
> 	预测意图及概率：[('C4', np.float32(0.49178484)), ('D1', np.float32(0.067849144)), ('A1', np.float32(0.06687233))
>
> C4:Hereditary（遗传性）,D1:Diet（饮食）,A1:（临床解释）

我觉得效果不好是没有很好的数据集。多意图识别可以考虑拉点别的数据集，暂时停一停把。

今日小总结，我在这个版本可以实现的方向：~~多意图识别~~，RAG评估，多路召回和重排序，多轮对话（追问），可更新的知识图谱，个性化回答（病人图谱）。

- 2024.12.19

更新`readme`文件

稍微修改`RAG.py`，~~实现多轮对话~~。

完成`RAG_Excel.py`，实现对Excel进行RAG。最初用的是`paraphrase-MiniLM-L6-v2`，但是效果奇差无比。

在后续的工作中可以尝试其他的embeding模型进行**对比评估**；也可以进行**多路召回和重排序**；可以考虑进行先**问题重述or意图识别再进行RAG**，PDF的知识非常专业，Excel的知识非常口语。

- 2024.12.16

更新RAG内容，调整RAG输出：

> **添加页码信息**：
>
> - 在 `extract_pdf_content` 中为每个页面的内容加上 `page_number` 属性。
> - 在输出结果时显示对应的页码。
>
> **合并更多内容**：
>
> - 在 `extract_pdf_content` 中，将每一页的所有段落合并为一个块，避免单独提取小段内容。
> - 在 `build_knowledge_base` 中按句号（`。`）再次分割大块内容，确保语义完整性。
>
> **输出详细内容**：
>
> - 输出检索结果时，显示完整的句子内容，不再截断

效果谈不上好，需要优化。

