# 基于知识图谱的糖尿病问答系统

## 1 项目介绍

知识图谱是目前自然语言处理的一个热门方向。本项目是立足医药领域，以天池瑞金数据集和Dacorp问答数据为基础使用neo4j构建知识图谱并完成问答系统。主体思路为：

![version2](img/version2.jpg)

RAG的数据融合了多个来源，包括PDF数据（ [国家基层糖尿病防治管理指南（ 2022）.pdf](data\国家基层糖尿病防治管理指南（ 2022）.pdf) ）、Excel数据（ [intent_detection.xlsx](data\intent_detection.xlsx) ）等。



- **重要提示**

本项目用到的模型在本地，文件过大没有上传。

## 2 运行环境

| environment | version |
| :---------: | :-----: |
|   Windows   |   11    |
|   Python    |   3.9   |
|   pytorch   |  2.4.1  |
|    neo4j    | 社区版  |
|  streamlit  | 1.41.1  |
|  langchain  | 0.3.13  |
|   openai    | 1.58.1  |

 

## 3 代码解释





## 4 工作进度

- 2025.2.26

完成DeBERTa部分的代码，更新test

- 2025.2.4

完成ELECTRA部分代码。

- 2025.1.3

拉huggingface代码完成实体识别。

实现web端QA界面的“问题重述”，“实体识别”，“意图识别”部分。



- 2025.1.2

实现web端的introduce、KGshow和QA部分内容。

实现langchain的部分内容（chain连接模块，流输出，带记忆的聊天（多轮对话））。

- 2024.12.28

在ack_LLM.py中，尝试了一下prompt进行**问题重述**，让他“提问你认为回答此文本提到的问题需要了解的专业问题”，LLM总是输出：

> 糖尿病的预防与治疗

“预防”，“治疗”属于两个类别，无奈进行多分类（意图）。编写multi_intent_detection_bert.py，使用BCE（内置SIGMOD）进行多意图识别，发现效果并不好。

> 代码原理是:
>
> **真实标签（labels）**：
>
> > [[1, 0, 0],  # 第一个样本的真实标签 
> >
> > [0, 1, 0]]  # 第二个样本的真实标签
>
> **Logits 输出**：
>
> > [[ 2.0, -1.5,  0.3],  # 第一个样本的 logits 
> >
> > [-0.8,  2.5, -3.0]]  # 第二个样本的 logits
>
> **Sigmoid 激活:**
>
> > torch.sigmoid([[ 2.0, -1.5,  0.3],               
> >
> > [-0.8,  2.5, -3.0]])
> >
> >  = [[0.8808, 0.1824, 0.5744], # 第一个样本的概率  
> >
> >  [0.3100, 0.9241, 0.0474]]  # 第二个样本的概率
>
>  **二值化：**
>
> > preds = [[1, 0, 1],  # 第一个样本的预测        
> >
> >  [0, 1, 0]]  # 第二个样本的预测
>
> **计算正确预测数**：
>
> > (preds == labels) = [[True, True, True],   # 第一个样本错了一个                     
> >
> > [True, True, True]]  # 第二个样本全对
> >
> >  正确数量 = 6（所有标签全对）
>
> accuracy = correct / total = 5 / 6 = 83.3（即 83.3% 准确率）
>
> ****

> 请输入问句（输入'退出'结束）：糖尿病如果进行检查，糖尿病会遗传给下一代吗
> 	预测意图及概率：[('C4', np.float32(0.49178484)), ('D1', np.float32(0.067849144)), ('A1', np.float32(0.06687233))
>
> C4:Hereditary（遗传性）,D1:Diet（饮食）,A1:（临床解释）

我觉得效果不好是没有很好的数据集。多意图识别可以考虑拉点别的数据集，暂时停一停把。

今日小总结，我在这个版本可以实现的方向：~~多意图识别~~，RAG评估，多路召回和重排序，多轮对话（追问），可更新的知识图谱，个性化回答（病人图谱）。

- 2024.12.19

更新`readme`文件

稍微修改`RAG.py`，~~实现多轮对话~~。

完成`RAG_Excel.py`，实现对Excel进行RAG。最初用的是`paraphrase-MiniLM-L6-v2`，但是效果奇差无比。

在后续的工作中可以尝试其他的embeding模型进行**对比评估**；也可以进行**多路召回和重排序**；可以考虑进行先**问题重述or意图识别再进行RAG**，PDF的知识非常专业，Excel的知识非常口语。

- 2024.12.16

更新RAG内容，调整RAG输出：

> **添加页码信息**：
>
> - 在 `extract_pdf_content` 中为每个页面的内容加上 `page_number` 属性。
> - 在输出结果时显示对应的页码。
>
> **合并更多内容**：
>
> - 在 `extract_pdf_content` 中，将每一页的所有段落合并为一个块，避免单独提取小段内容。
> - 在 `build_knowledge_base` 中按句号（`。`）再次分割大块内容，确保语义完整性。
>
> **输出详细内容**：
>
> - 输出检索结果时，显示完整的句子内容，不再截断

效果谈不上好，需要优化。

